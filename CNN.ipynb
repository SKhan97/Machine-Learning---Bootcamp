{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/SKhan97/Machine-Learning---Bootcamp/blob/master/CNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_URWRaFrFm7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "53E-Y3axG47a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import Variable\n",
        "import torchvision #Classic data sets \n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpI-AKvCHJJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1962
        },
        "outputId": "5100c018-23b2-43f4-b2ae-1b761728bbff"
      },
      "cell_type": "code",
      "source": [
        "training_data = datasets.MNIST(root='data/',\n",
        "                            transform = transforms.ToTensor(),\n",
        "                            train = True,\n",
        "                            download = True) \n",
        "\n",
        "test_data = datasets.MNIST(root='data/',\n",
        "                            transform = transforms.ToTensor(),\n",
        "                            train = False,\n",
        "                            download = True)\n",
        "\n",
        "print(training_data[0][0][0])\n",
        "\n",
        "plt.imshow(training_data[0][0][0],cmap = 'gray_r')\n",
        "plt.show()\n",
        "\n",
        "print('Number of training points', len(training_data))\n",
        "print('Number of testing points', len(test_data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "\n",
            "Columns 0 to 9 \n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1176  0.1412\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1922  0.9333  0.9922\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0706  0.8588  0.9922\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3137  0.6118\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0549\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0902  0.2588\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0706  0.6706  0.8588  0.9922\n",
            " 0.0000  0.0000  0.0000  0.0000  0.2157  0.6745  0.8863  0.9922  0.9922  0.9922\n",
            " 0.0000  0.0000  0.0000  0.0000  0.5333  0.9922  0.9922  0.9922  0.8314  0.5294\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            "\n",
            "Columns 10 to 19 \n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0118  0.0706  0.0706  0.0706  0.4941  0.5333  0.6863  0.1020\n",
            " 0.3686  0.6039  0.6667  0.9922  0.9922  0.9922  0.9922  0.9922  0.8824  0.6745\n",
            " 0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9843  0.3647  0.3216\n",
            " 0.9922  0.9922  0.9922  0.9922  0.7765  0.7137  0.9686  0.9451  0.0000  0.0000\n",
            " 0.4196  0.9922  0.9922  0.8039  0.0431  0.0000  0.1686  0.6039  0.0000  0.0000\n",
            " 0.0039  0.6039  0.9922  0.3529  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.5451  0.9922  0.7451  0.0078  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0431  0.7451  0.9922  0.2745  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.1373  0.9451  0.8824  0.6275  0.4235  0.0039  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.3176  0.9412  0.9922  0.9922  0.4667  0.0980  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.1765  0.7294  0.9922  0.9922  0.5882  0.1059\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0627  0.3647  0.9882  0.9922  0.7333\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.9765  0.9922  0.9765\n",
            " 0.0000  0.0000  0.0000  0.0000  0.1804  0.5098  0.7176  0.9922  0.9922  0.8118\n",
            " 0.0000  0.0000  0.1529  0.5804  0.8980  0.9922  0.9922  0.9922  0.9804  0.7137\n",
            " 0.0941  0.4471  0.8667  0.9922  0.9922  0.9922  0.9922  0.7882  0.3059  0.0000\n",
            " 0.8353  0.9922  0.9922  0.9922  0.9922  0.7765  0.3176  0.0078  0.0000  0.0000\n",
            " 0.9922  0.9922  0.9922  0.7647  0.3137  0.0353  0.0000  0.0000  0.0000  0.0000\n",
            " 0.9922  0.9569  0.5216  0.0431  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.5176  0.0627  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            "\n",
            "Columns 20 to 27 \n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.6510  1.0000  0.9686  0.4980  0.0000  0.0000  0.0000  0.0000\n",
            " 0.9922  0.9490  0.7647  0.2510  0.0000  0.0000  0.0000  0.0000\n",
            " 0.3216  0.2196  0.1529  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.2510  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0078  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
            "[torch.FloatTensor of size 28x28]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fac757a2208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of training points 60000\n",
            "Number of testing points 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NdSkfcVyHxs4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "#Generators\n",
        "training_samples = torch.utils.data.DataLoader(dataset = training_data,\n",
        "                                              batch_size = batch_size,\n",
        "                                              shuffle = True) #Will shuffle after each time it trains\n",
        "\n",
        "test_samples = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                              batch_size = batch_size,\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMdK4Pw4IpFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class convnet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=5, stride=1) #Number of input channels (if colour then 3 because RGB), number of output channels, size of filter to apply, how much to shift filter by after doing dot product\n",
        "    self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=5, stride=1)\n",
        "    self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=5, stride=1)\n",
        "    self.dense1 = torch.nn.Linear(32768,10) #Flattened at end so input to end is 32768 (to find out can just print x.shape after each relu) \n",
        "    \n",
        "    self.bn1 = torch.nn.BatchNorm2d(32)\n",
        "    self.bn2 = torch.nn.BatchNorm2d(64)\n",
        "    self.bn3 = torch.nn.BatchNorm2d(128)\n",
        "    \n",
        "  def selu(self,x):\n",
        "    scale = 1.0507009873554804934193349852946\n",
        "    alpha = 1.6732632423543772848170429916717\n",
        "    x[x>0] = scale*x\n",
        "    x[x<=0] = scale*(alpha*x.exp() - alpha)\n",
        "    return x\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x))).view(x.shape[0],-1) #Flattens it to basically get a 2d vector\n",
        "    \n",
        "    x = F.softmax(self.dense1(x), dim = 1) #Chooses highest value at the end and dim = 1 means that sum has to be 1\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZHy_WHWKVq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 0.00075\n",
        "epochs = 1 #Only 1 iteration because 60,000 data points should be enough to train\n",
        "\n",
        "cnn = convnet()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(cnn.parameters(),lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIRlaq54Krhk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epochs):\n",
        "  costs = []\n",
        "  \n",
        "  \n",
        "  for e in range(epochs):\n",
        "    for i, (x,y) in enumerate(training_samples): #enumerate gives current batch as i\n",
        "      x, y = Variable(x), Variable(y)\n",
        "\n",
        "      h = cnn.forward(x)\n",
        "      cost = criterion(h, y)\n",
        "      \n",
        "      optimiser.zero_grad()\n",
        "      cost.backward()\n",
        "      optimiser.step()\n",
        "      \n",
        "      costs.append(cost.data[0])\n",
        "      \n",
        "      #print('Epoch: ', e, 'Batch: ', i, 'Cost', cost.data[0])\n",
        "      \n",
        "train(epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmQ1SCzRLwxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "761f909e-f3f6-4649-b79d-9a8a7773f840"
      },
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  print('Started evaluation...')\n",
        "  cnn.eval()\n",
        "  \n",
        "  correct = 0\n",
        "  for x, y in test_samples:\n",
        "    x = Variable(x) #Don't need to turn label into variable because we aren't trying to calculate cost, just what kind of number it is\n",
        "    \n",
        "    h = cnn.forward(x)\n",
        "    pred = h.data.max(1)[1] #Will give probabilites and output so want [1] because aren't interested in probabilities but in fact the label associated with it\n",
        "                            # the (1) tells you it is across each row, not each column (specifies the axis)\n",
        "    correct += pred.eq(y).sum()\n",
        "  \n",
        "  return correct/len(test_data)\n",
        "\n",
        "test()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started evaluation...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "pH6b4I-TNvDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}